{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a6e7eb",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model\n",
    "\n",
    "The GradientBoostingClassifier is a machine learning model for recognizing face emotions. It is a member of the gradient boosting algorithm family and is noted for its ability to handle complex datasets and build high-performance models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54623cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633eaad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fer2013.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646d4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into train, val, test sets\n",
    "train_data = data[data.Usage == 'Training']\n",
    "test_data = data[data.Usage == 'PrivateTest']\n",
    "val_data = data[data.Usage == 'PublicTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b141bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing images\n",
    "def preprocess(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data)):\n",
    "        img = data.iloc[i]['pixels'].split(' ')\n",
    "        img = np.array(img, dtype='float32')\n",
    "        img = img / 255.0\n",
    "        X.append(img)\n",
    "        y.append(data.iloc[i]['emotion'])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = preprocess(train_data)\n",
    "X_val, y_val = preprocess(val_data)\n",
    "X_test, y_test = preprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ac4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9c2c9",
   "metadata": {},
   "source": [
    "n_estimators: we can use this to specify the number of boosting stages or decision trees to create. In our situation, we set it to 200, which means 200 decision trees will be generated.\n",
    "\n",
    "max_depth: The maximum depth of each decision tree is determined by this option. A larger value, such as 20, allows the trees to have more splits and capture more intricate data linkages. We fixed on this number after trying several depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72355d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=200, max_depth=20, learning_rate=0.1, validation_fraction=0.2, n_iter_no_change=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f89c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3874         3305.64m\n",
      "         2           1.1312         2802.75m\n",
      "         3           0.9473         2631.97m\n",
      "         4           0.8068         2538.11m\n",
      "         5           0.6900         2484.26m\n",
      "         6           0.5914         2476.54m\n",
      "         7           0.5078         2427.32m\n",
      "         8           0.4333         2387.64m\n",
      "         9           0.3722         2352.74m\n",
      "        10           0.3204         2322.87m\n",
      "        20           0.0701         2090.24m\n",
      "        30           0.0164         1959.93m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=20, n_estimators=200, n_iter_no_change=10,\n",
       "                           validation_fraction=0.2, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f74317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efee99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e0c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.93      0.84      0.88      3995\n",
      "     Disgust       0.81      0.84      0.83       436\n",
      "        Fear       0.91      0.85      0.88      4097\n",
      "       Happy       0.85      0.94      0.89      7215\n",
      "         Sad       0.86      0.86      0.86      4830\n",
      "    Surprise       0.95      0.90      0.92      3171\n",
      "     Neutral       0.87      0.87      0.87      4965\n",
      "\n",
      "    accuracy                           0.88     28709\n",
      "   macro avg       0.88      0.87      0.88     28709\n",
      "weighted avg       0.88      0.88      0.88     28709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "print('Training Classification')\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names, labels=[0, 1, 2, 3, 4, 5, 6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f08362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43382557815547507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.25      0.32       491\n",
      "           1       0.23      0.35      0.28        55\n",
      "           2       0.41      0.25      0.31       528\n",
      "           3       0.47      0.71      0.56       879\n",
      "           4       0.31      0.32      0.31       594\n",
      "           5       0.71      0.53      0.61       416\n",
      "           6       0.39      0.39      0.39       626\n",
      "\n",
      "    accuracy                           0.43      3589\n",
      "   macro avg       0.42      0.40      0.40      3589\n",
      "weighted avg       0.44      0.43      0.42      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668d5b9",
   "metadata": {},
   "source": [
    "The model's performance is average, with F1-scores ranging from 0.28 to 0.61 for various emotion categories. It is struggling to correctly predicting minority classes (Disgust and Fear) while performing well on majority classes (Happy, Surprise). The macro average F1-score is 0.40, indicating a moderate overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda4d6b6",
   "metadata": {},
   "source": [
    "Below We are using a feature selection technique called the SelectFromModel class from scikit-learn. The underlying estimators for feature selection are the LassoCV and RidgeCV models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a939f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91665172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectFromModel(LassoCV())\n",
    "selector = SelectFromModel(RidgeCV())\n",
    "\n",
    "# creating pipeline with selector and GradientBoostingClassifier\n",
    "clf = make_pipeline(selector, GradientBoostingClassifier(n_estimators=200, max_depth=20, learning_rate=0.1, validation_fraction=0.2, n_iter_no_change=10, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983a4e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3764          878.43m\n",
      "         2           1.1188          901.41m\n",
      "         3           0.9361          907.05m\n",
      "         4           0.7881          908.13m\n",
      "         5           0.6686          908.08m\n",
      "         6           0.5712          903.18m\n",
      "         7           0.4873          898.85m\n",
      "         8           0.4172          895.48m\n",
      "         9           0.3577          883.75m\n",
      "        10           0.3065          856.54m\n",
      "        20           0.0656          711.89m\n",
      "        30           0.0154          640.53m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('selectfrommodel',\n",
       "                 SelectFromModel(estimator=RidgeCV(alphas=array([ 0.1,  1. , 10. ])))),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(max_depth=20, n_estimators=200,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            validation_fraction=0.2,\n",
       "                                            verbose=1))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce91dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621e7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11851e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.91      0.84      0.88      3995\n",
      "     Disgust       0.80      0.86      0.83       436\n",
      "        Fear       0.92      0.85      0.88      4097\n",
      "       Happy       0.85      0.94      0.89      7215\n",
      "         Sad       0.87      0.86      0.86      4830\n",
      "    Surprise       0.94      0.90      0.92      3171\n",
      "     Neutral       0.87      0.87      0.87      4965\n",
      "\n",
      "    accuracy                           0.88     28709\n",
      "   macro avg       0.88      0.88      0.88     28709\n",
      "weighted avg       0.89      0.88      0.88     28709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "print('Training Classification')\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names, labels=[0, 1, 2, 3, 4, 5, 6]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43162908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42490944552800225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.24      0.29       491\n",
      "           1       0.26      0.33      0.29        55\n",
      "           2       0.40      0.24      0.30       528\n",
      "           3       0.45      0.69      0.55       879\n",
      "           4       0.31      0.31      0.31       594\n",
      "           5       0.68      0.51      0.59       416\n",
      "           6       0.40      0.41      0.40       626\n",
      "\n",
      "    accuracy                           0.42      3589\n",
      "   macro avg       0.41      0.39      0.39      3589\n",
      "weighted avg       0.43      0.42      0.41      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38deb6f0",
   "metadata": {},
   "source": [
    "The model performs to similar to previous models with slight dip , with F1-scores ranging from 0.29 to 0.59 for various emotion categories. It still struggles to forecast the minority classes (Disgust and Fear) while performing quite well on the majority classes (Happy, Surprise). The macro average F1-score stays at 0.39, indicating a moderate overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82ba31db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosting_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"boosting_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
